from flask import Flask, request, jsonify
from flask_cors import CORS
import logging
from datetime import datetime
from typing import Dict, List, Any
import os
import json
from dotenv import load_dotenv
import openai
from pathlib import Path

load_dotenv()

app = Flask(__name__)
CORS(app)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

REPORT_DIRS = {
    'NORMAL': 'report/valid',
    'EXCEPTION': 'report/invalid', 
    'ATTACK': 'report/attack'
}

for dir_path in REPORT_DIRS.values():
    Path(dir_path).mkdir(parents=True, exist_ok=True)

class SecurityAnalysisSystem:
    def __init__(self):
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.use_mock = not bool(self.openai_api_key)
        
        if self.openai_api_key:
            openai.api_key = self.openai_api_key
            logger.info("OpenAI API initialized")
        else:
            logger.info("Using mock analysis mode")
            
    def generate_simple_report(self, analysis: Dict[str, Any], log_data: Dict[str, Any]) -> str:
        classification = analysis.get("classification", "UNKNOWN")
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"simple_report_{timestamp}.md"
        
        if classification == "EXCEPTION":
            report_dir = REPORT_DIRS["EXCEPTION"]
        else:
            report_dir = REPORT_DIRS["NORMAL"]
        
        report_content = f"""
    # ê°„ë‹¨ ë³´ê³ ì„œ

    **ìƒì„±ì¼ì‹œ:** {datetime.now().strftime("%Yë…„ %mì›” %dì¼ %H:%M:%S")}
    **ë¶„ë¥˜:** {classification}
    **ìœ„í—˜ë„:** {analysis.get('threat_level', 'UNKNOWN')}
    **ì‚¬ìš©ì:** {log_data.get('user_id', 'N/A')}
    **URL:** {log_data.get('request_url', 'N/A')}
    **ê²°ê³¼:** {log_data.get('access_result', 'N/A')}

    ## ê¶Œì¥ì‚¬í•­
    {chr(10).join(f"- {rec}" for rec in analysis.get('recommendations', ['ì—†ìŒ']))}
    """
        
        report_path = os.path.join(report_dir, filename)
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"ê°„ë‹¨ ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {report_path}")
        return report_path
    
    def analyze_log_with_llm(self, log_data: Dict[str, Any]) -> Dict[str, Any]:
        try:
            base_analysis = self.analyze_log(log_data)
            llm_analysis = self._get_llm_analysis(log_data, base_analysis)
            
            final_analysis = {
                **base_analysis,
                "llm_analysis": llm_analysis,
                "enhanced_classification": llm_analysis.get("classification", base_analysis["classification"]),
                "enhanced_threat_level": llm_analysis.get("threat_level", base_analysis["threat_level"])
            }
            
            report_path = self._generate_and_save_report(final_analysis, log_data)
            final_analysis["report_path"] = report_path
            
            return final_analysis
            
        except Exception as e:
            logger.error(f"LLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return self.analyze_log(log_data)
    
    def _get_llm_analysis(self, log_data: Dict[str, Any], base_analysis: Dict[str, Any]) -> Dict[str, Any]:
        if self.use_mock:
            return self._mock_llm_analysis(log_data, base_analysis)
        
        try:
            prompt = self._create_analysis_prompt(log_data, base_analysis)
            
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "You are a cybersecurity expert analyzing security logs."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1500,
                temperature=0.3
            )
            
            analysis_text = response.choices[0].message.content
            return self._parse_llm_response(analysis_text)
            
        except Exception as e:
            logger.error(f"OpenAI API í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}")
            return self._mock_llm_analysis(log_data, base_analysis)
    
    def _mock_llm_analysis(self, log_data: Dict[str, Any], base_analysis: Dict[str, Any]) -> Dict[str, Any]:
        classification = base_analysis.get("classification", "UNKNOWN")
        
        if classification == "ATTACK":
            return {
                "classification": "ATTACK",
                "threat_level": "HIGH",
                "when": log_data.get("timestamp", "Unknown"),
                "what": f"ì•…ì˜ì ì¸ ìš”ì²­ íƒì§€: {', '.join(base_analysis.get('attack_indicators', []))}",
                "who": f"ì‚¬ìš©ì ID: {log_data.get('user_id', 'Unknown')}",
                "how": f"ê³µê²© ê²½ë¡œ: {log_data.get('request_url', 'Unknown')}",
                "countermeasures": [
                    "ì¦‰ì‹œ í•´ë‹¹ IP ì£¼ì†Œ ì°¨ë‹¨",
                    "ë³´ì•ˆ íŒ€ ê¸´ê¸‰ ì•Œë¦¼",
                    "ê´€ë ¨ ë¡œê·¸ ì¶”ê°€ ë¶„ì„",
                    "ì‹œìŠ¤í…œ ì·¨ì•½ì  íŒ¨ì¹˜ ì ìš©"
                ]
            }
        elif classification == "EXCEPTION":
            return {
                "classification": "EXCEPTION",
                "threat_level": "LOW",
                "reason": "ê¶Œí•œ ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ì ‘ê·¼ ê±°ë¶€",
                "user_info": f"ì‚¬ìš©ì: {log_data.get('user_id', 'Unknown')} (ì—­í• : {log_data.get('user_role', 'Unknown')})",
                "attempted_action": log_data.get('action_type', 'Unknown'),
                "recommendations": [
                    "ì‚¬ìš©ì ê¶Œí•œ ì¬ê²€í† ",
                    "ì ‘ê·¼ ì œì–´ ì •ì±… í™•ì¸",
                    "ì‚¬ìš©ì êµìœ¡ í•„ìš”ì„± ê²€í† "
                ]
            }
        else:
            return {
                "classification": "NORMAL",
                "threat_level": "LOW",
                "status": "ì •ìƒì ì¸ ì ‘ê·¼ ìš”ì²­",
                "user_activity": f"{log_data.get('user_id', 'Unknown')}ì˜ {log_data.get('action_type', 'Unknown')} ìš”ì²­",
                "recommendations": [
                    "ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ ìœ ì§€",
                    "ì •ìƒ í™œë™ íŒ¨í„´ í•™ìŠµ"
                ]
            }
    
    def _create_analysis_prompt(self, log_data: Dict[str, Any], base_analysis: Dict[str, Any]) -> str:
        return f"""
ë‹¤ìŒ ë³´ì•ˆ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ê³  í•œêµ­ì–´ë¡œ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

ë¡œê·¸ ë°ì´í„°:
{json.dumps(log_data, indent=2, ensure_ascii=False)}

ê¸°ë³¸ ë¶„ì„ ê²°ê³¼:
{json.dumps(base_analysis, indent=2, ensure_ascii=False)}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
1. ë¶„ë¥˜: NORMAL/EXCEPTION/ATTACK ì¤‘ í•˜ë‚˜
2. ìœ„í˜‘ ìˆ˜ì¤€: LOW/MEDIUM/HIGH ì¤‘ í•˜ë‚˜
3. ê³µê²©ì¸ ê²½ìš°: When(ì–¸ì œ), What(ë¬´ì—‡ì„), Who(ëˆ„ê°€), How(ì–´ë–»ê²Œ)
4. ëŒ€ì‘ ë°©ì•ˆ ë˜ëŠ” ê¶Œì¥ì‚¬í•­

JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
"""
    
    def _parse_llm_response(self, response_text: str) -> Dict[str, Any]:
        try:
            if "{" in response_text:
                json_start = response_text.find("{")
                json_end = response_text.rfind("}") + 1
                json_text = response_text[json_start:json_end]
                return json.loads(json_text)
            else:
                return {"analysis": response_text}
        except:
            return {"analysis": response_text}
    
    def _generate_and_save_report(self, analysis: Dict[str, Any], log_data: Dict[str, Any]) -> str:
        classification = analysis.get("enhanced_classification", analysis.get("classification", "UNKNOWN"))
        
        report_content = self._create_report_content(analysis, log_data)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"security_report_{timestamp}.md"
        
        if classification == "ATTACK":
            report_dir = REPORT_DIRS["ATTACK"]
        elif classification == "EXCEPTION":
            report_dir = REPORT_DIRS["EXCEPTION"]
        else:
            report_dir = REPORT_DIRS["NORMAL"]
        
        report_path = os.path.join(report_dir, filename)
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {report_path}")
        return report_path
    
    def _create_report_content(self, analysis: Dict[str, Any], log_data: Dict[str, Any]) -> str:
        classification = analysis.get("enhanced_classification", analysis.get("classification", "UNKNOWN"))
        timestamp = datetime.now().strftime("%Yë…„ %mì›” %dì¼ %H:%M:%S")
        
        if classification == "ATTACK":
            return self._create_attack_report(analysis, log_data, timestamp)
        elif classification == "EXCEPTION":
            return self._create_exception_report(analysis, log_data, timestamp)
        else:
            return self._create_normal_report(analysis, log_data, timestamp)
    
    def _create_attack_report(self, analysis: Dict[str, Any], log_data: Dict[str, Any], timestamp: str) -> str:
        llm_analysis = analysis.get("llm_analysis", {})
        
        return f"""
# ë³´ì•ˆ ì‚¬ê³  ë³´ê³ ì„œ

**ë³´ê³ ì„œ ìƒì„±ì¼ì‹œ:** {timestamp}  
**ë¶„ë¥˜:** ğŸš¨ ë³´ì•ˆ ìœ„í˜‘ (ê³µê²©)  
**ìœ„í—˜ë„:** {analysis.get('enhanced_threat_level', 'HIGH')}  
**ì‹ ë¢°ë„:** {analysis.get('confidence', 0) * 100:.1f}%

---

## 1. ì‚¬ê³  ê°œìš”

### ğŸ“‹ ê¸°ë³¸ ì •ë³´
- **ë¡œê·¸ ID:** {log_data.get('timestamp', 'N/A')}
- **íƒì§€ ì‹œê°:** {log_data.get('timestamp', 'N/A')}
- **ë¶„ì„ ì™„ë£Œ ì‹œê°:** {analysis.get('timestamp', 'N/A')}

### ğŸ¯ ê³µê²© ì •ë³´ (5W1H)
- **When (ì–¸ì œ):** {llm_analysis.get('when', log_data.get('timestamp', 'N/A'))}
- **Who (ëˆ„ê°€):** {llm_analysis.get('who', f"ì‚¬ìš©ì ID: {log_data.get('user_id', 'Unknown')}")}
- **What (ë¬´ì—‡ì„):** {llm_analysis.get('what', 'ì•…ì˜ì ì¸ ìš”ì²­ íƒì§€')}
- **Where (ì–´ë””ì„œ):** {log_data.get('request_url', 'N/A')}
- **Why (ì™œ):** ì‹œìŠ¤í…œ ì¹¨í•´ ë˜ëŠ” ì •ë³´ íƒˆì·¨ ëª©ì ìœ¼ë¡œ ì¶”ì •
- **How (ì–´ë–»ê²Œ):** {llm_analysis.get('how', 'ê³µê²© ê¸°ë²• ë¶„ì„ ì¤‘')}

---

## 2. ìƒì„¸ ë¶„ì„

### ğŸ” íƒì§€ëœ ê³µê²© ìœ í˜•
{chr(10).join(f"- {indicator}" for indicator in analysis.get('attack_indicators', ['ì •ë³´ ì—†ìŒ']))}

### ğŸ“Š ìš”ì²­ ìƒì„¸ ì •ë³´
- **HTTP ë©”ì„œë“œ:** {log_data.get('request_method', 'N/A')}
- **ìš”ì²­ URL:** {log_data.get('request_url', 'N/A')}
- **ì‚¬ìš©ì ì—­í• :** {log_data.get('user_role', 'N/A')}
- **ìš”ì²­ ê²°ê³¼:** {log_data.get('access_result', 'N/A')}
- **ë¬¸ì„œ ë¶„ë¥˜:** {log_data.get('document_classification', 'N/A')}

### ğŸ”’ ë³´ì•ˆ ì´ë²¤íŠ¸
{chr(10).join(f"- {event}" for event in log_data.get('security_events', ['ì—†ìŒ']))}

---

## 3. ì˜í–¥ í‰ê°€

### ğŸ’¥ ì ì¬ì  í”¼í•´
- **ì˜í–¥ ìˆ˜ì¤€:** {analysis.get('detailed_analysis', {}).get('potential_impact', 'MEDIUM')}
- **ì˜í–¥ ë°›ì€ ìì›:**
{chr(10).join(f"  - {resource}" for resource in analysis.get('detailed_analysis', {}).get('affected_resources', ['ì •ë³´ ì—†ìŒ']))}

---

## 4. ëŒ€ì‘ ë°©ì•ˆ

### ğŸš¨ ì¦‰ì‹œ ëŒ€ì‘ ì¡°ì¹˜
{chr(10).join(f"- {rec}" for rec in llm_analysis.get('countermeasures', analysis.get('recommendations', ['ëŒ€ì‘ ë°©ì•ˆ ê²€í†  ì¤‘'])))}

### ğŸ“‹ í›„ì† ì¡°ì¹˜
- [ ] ì‚¬ê³  ëŒ€ì‘ íŒ€ ì†Œì§‘
- [ ] í¬ë Œì‹ ë¶„ì„ ìˆ˜í–‰
- [ ] ê´€ë ¨ ì‹œìŠ¤í…œ ë³´ì•ˆ ì ê²€
- [ ] ì‚¬ìš©ì êµìœ¡ ë° ì •ì±… ì—…ë°ì´íŠ¸

---

## 5. ê²°ë¡  ë° ê¶Œê³ ì‚¬í•­

ì´ ë³´ì•ˆ ì‚¬ê³ ëŠ” **{analysis.get('enhanced_threat_level', 'HIGH')}** ìœ„í—˜ë„ë¡œ ë¶„ë¥˜ë˜ë©°, ì¦‰ì‹œ ëŒ€ì‘ì´ í•„ìš”í•©ë‹ˆë‹¤.

**ì£¼ìš” ê¶Œê³ ì‚¬í•­:**
1. ì¦‰ì‹œ í•´ë‹¹ IP ì£¼ì†Œ ì°¨ë‹¨
2. ë³´ì•ˆ íŒ€ ê¸´ê¸‰ ì†Œì§‘
3. ì‹œìŠ¤í…œ ì·¨ì•½ì  ì ê²€ ë° íŒ¨ì¹˜
4. ëª¨ë‹ˆí„°ë§ ê°•í™”

---

**ë³´ê³ ì„œ ì‘ì„±:** ë³´ì•ˆ ë¶„ì„ ì‹œìŠ¤í…œ  
**ê²€í†  í•„ìš”:** ë³´ì•ˆ ë‹´ë‹¹ì  
**ë°°í¬:** ê²½ì˜ì§„, IT ë³´ì•ˆíŒ€
"""

    def _create_exception_report(self, analysis: Dict[str, Any], log_data: Dict[str, Any], timestamp: str) -> str:
        llm_analysis = analysis.get("llm_analysis", {})
        
        return f"""
# ì ‘ê·¼ ì œì–´ ë³´ê³ ì„œ

**ë³´ê³ ì„œ ìƒì„±ì¼ì‹œ:** {timestamp}  
**ë¶„ë¥˜:** âš ï¸ ì ‘ê·¼ ê±°ë¶€  
**ìœ„í—˜ë„:** {analysis.get('enhanced_threat_level', 'LOW')}  
**ì‹ ë¢°ë„:** {analysis.get('confidence', 0) * 100:.1f}%

---

## 1. ì‚¬ê±´ ê°œìš”

### ğŸ“‹ ê¸°ë³¸ ì •ë³´
- **ë¡œê·¸ ID:** {log_data.get('timestamp', 'N/A')}
- **ë°œìƒ ì‹œê°:** {log_data.get('timestamp', 'N/A')}
- **ë¶„ì„ ì™„ë£Œ ì‹œê°:** {analysis.get('timestamp', 'N/A')}

### ğŸ‘¤ ì‚¬ìš©ì ì •ë³´
- **ì‚¬ìš©ì ID:** {log_data.get('user_id', 'N/A')}
- **ì‚¬ìš©ì ì—­í• :** {log_data.get('user_role', 'N/A')}
- **ì‹œë„í•œ ì‘ì—…:** {log_data.get('action_type', 'N/A')}

---

## 2. ì ‘ê·¼ ê±°ë¶€ ìƒì„¸

### ğŸš« ê±°ë¶€ ì‚¬ìœ 
{llm_analysis.get('reason', 'ê¶Œí•œ ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ì ‘ê·¼ ê±°ë¶€')}

### ğŸ“Š ìš”ì²­ ì •ë³´
- **HTTP ë©”ì„œë“œ:** {log_data.get('request_method', 'N/A')}
- **ìš”ì²­ URL:** {log_data.get('request_url', 'N/A')}
- **ë¬¸ì„œ ë¶„ë¥˜:** {log_data.get('document_classification', 'N/A')}
- **ì ‘ê·¼ ê²°ê³¼:** {log_data.get('access_result', 'N/A')}

---

## 3. ë¶„ì„ ê²°ê³¼

### ğŸ“ˆ ìœ„í—˜ í‰ê°€
- **ë³´ì•ˆ ìœ„í—˜ë„:** ë‚®ìŒ
- **ì •ì±… ìœ„ë°˜ ì—¬ë¶€:** ì—†ìŒ
- **ì¶”ê°€ ì¡°ì‚¬ í•„ìš”ì„±:** ë‚®ìŒ

### ğŸ” íŒ¨í„´ ë¶„ì„
ì •ìƒì ì¸ ê¶Œí•œ ì œì–´ ì‹œìŠ¤í…œ ì‘ë™ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.

---

## 4. ê¶Œì¥ ì¡°ì¹˜

### ğŸ“‹ ì¦‰ì‹œ ì¡°ì¹˜
{chr(10).join(f"- {rec}" for rec in llm_analysis.get('recommendations', analysis.get('recommendations', ['ê¶Œí•œ ì„¤ì • í™•ì¸'])))}

### ğŸ”„ í›„ì† ì¡°ì¹˜
- [ ] ì‚¬ìš©ì ê¶Œí•œ ì¬ê²€í† 
- [ ] í•„ìš”ì‹œ ê¶Œí•œ ì¡°ì •
- [ ] ì‚¬ìš©ì êµìœ¡ ì‹¤ì‹œ

---

## 5. ê²°ë¡ 

ì´ ì‚¬ê±´ì€ ì •ìƒì ì¸ ì ‘ê·¼ ì œì–´ ì‹œìŠ¤í…œì˜ ì‘ë™ìœ¼ë¡œ, ì¶”ê°€ì ì¸ ë³´ì•ˆ ìœ„í˜‘ì€ ì—†ëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.

**ê¶Œê³ ì‚¬í•­:**
1. í˜„ì¬ ê¶Œí•œ ì •ì±… ìœ ì§€
2. ì •ê¸°ì ì¸ ê¶Œí•œ ê²€í† 
3. ì‚¬ìš©ì êµìœ¡ ì§€ì†

---

**ë³´ê³ ì„œ ì‘ì„±:** ë³´ì•ˆ ë¶„ì„ ì‹œìŠ¤í…œ  
**ê²€í†  í•„ìš”:** ì‹œìŠ¤í…œ ê´€ë¦¬ì  
**ë°°í¬:** IT ê´€ë¦¬íŒ€
"""

    def _create_normal_report(self, analysis: Dict[str, Any], log_data: Dict[str, Any], timestamp: str) -> str:
        llm_analysis = analysis.get("llm_analysis", {})
        
        return f"""
# ì •ìƒ ì ‘ê·¼ ë³´ê³ ì„œ

**ë³´ê³ ì„œ ìƒì„±ì¼ì‹œ:** {timestamp}  
**ë¶„ë¥˜:** âœ… ì •ìƒ í™œë™  
**ìœ„í—˜ë„:** {analysis.get('enhanced_threat_level', 'LOW')}  
**ì‹ ë¢°ë„:** {analysis.get('confidence', 0) * 100:.1f}%

---

## 1. í™œë™ ê°œìš”

### ğŸ“‹ ê¸°ë³¸ ì •ë³´
- **ë¡œê·¸ ID:** {log_data.get('timestamp', 'N/A')}
- **ì ‘ê·¼ ì‹œê°:** {log_data.get('timestamp', 'N/A')}
- **ë¶„ì„ ì™„ë£Œ ì‹œê°:** {analysis.get('timestamp', 'N/A')}

### ğŸ‘¤ ì‚¬ìš©ì ì •ë³´
- **ì‚¬ìš©ì ID:** {log_data.get('user_id', 'N/A')}
- **ì‚¬ìš©ì ì—­í• :** {log_data.get('user_role', 'N/A')}
- **ìˆ˜í–‰ ì‘ì—…:** {log_data.get('action_type', 'N/A')}

---

## 2. í™œë™ ìƒì„¸

### ğŸ“Š ìš”ì²­ ì •ë³´
- **HTTP ë©”ì„œë“œ:** {log_data.get('request_method', 'N/A')}
- **ìš”ì²­ URL:** {log_data.get('request_url', 'N/A')}
- **ë¬¸ì„œ ë¶„ë¥˜:** {log_data.get('document_classification', 'N/A')}
- **ì ‘ê·¼ ê²°ê³¼:** {log_data.get('access_result', 'N/A')}

### âœ… ì •ìƒ í™œë™ í™•ì¸
{llm_analysis.get('status', 'ì •ìƒì ì¸ ì ‘ê·¼ ìš”ì²­ìœ¼ë¡œ í™•ì¸ë¨')}

---

## 3. ë¶„ì„ ê²°ê³¼

### ğŸ“ˆ ë³´ì•ˆ í‰ê°€
- **ìœ„í—˜ ì§€í‘œ:** ì—†ìŒ
- **ì´ìƒ í–‰ë™:** íƒì§€ë˜ì§€ ì•ŠìŒ
- **ì •ì±… ì¤€ìˆ˜:** ì ì ˆ

### ğŸ” í™œë™ íŒ¨í„´
ì‚¬ìš©ìì˜ ì •ìƒì ì¸ ì—…ë¬´ í™œë™ íŒ¨í„´ì— ë¶€í•©í•©ë‹ˆë‹¤.

---

## 4. ê¶Œì¥ ì‚¬í•­

### ğŸ“‹ ëª¨ë‹ˆí„°ë§ ì§€ì†
{chr(10).join(f"- {rec}" for rec in llm_analysis.get('recommendations', analysis.get('recommendations', ['ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ ìœ ì§€'])))}

### ğŸ”„ ì‹œìŠ¤í…œ ìš´ì˜
- [ ] ì •ìƒ í™œë™ íŒ¨í„´ í•™ìŠµ
- [ ] ë² ì´ìŠ¤ë¼ì¸ ì—…ë°ì´íŠ¸
- [ ] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

---

## 5. ê²°ë¡ 

ì´ í™œë™ì€ ì •ìƒì ì¸ ì‚¬ìš©ì ì ‘ê·¼ìœ¼ë¡œ ë¶„ë¥˜ë˜ë©°, ì¶”ê°€ì ì¸ ì¡°ì¹˜ê°€ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

**í˜„ì¬ ìƒíƒœ:** ì–‘í˜¸  
**ê¶Œê³ ì‚¬í•­:** í˜„ì¬ ë³´ì•ˆ ì •ì±… ìœ ì§€

---

**ë³´ê³ ì„œ ì‘ì„±:** ë³´ì•ˆ ë¶„ì„ ì‹œìŠ¤í…œ  
**ê²€í†  í•„ìš”:** í•´ë‹¹ ì—†ìŒ  
**ë°°í¬:** ë¡œê·¸ ë³´ê´€ì†Œ
"""

    def analyze_log(self, log_data: Dict[str, Any]) -> Dict[str, Any]:
        try:
            attack_indicators = self._detect_attack_patterns(log_data)
            classification, threat_level = self._classify_request(log_data, attack_indicators)
            
            confidence = self._calculate_confidence(log_data, attack_indicators)
            
            recommendations = self._generate_recommendations(classification, attack_indicators, threat_level)
            
            detailed_analysis = {}
            if classification == "ATTACK":
                detailed_analysis = self._detailed_threat_analysis(log_data)
            
            return {
                "timestamp": datetime.now().isoformat(),
                "log_id": log_data.get("timestamp", ""),
                "classification": classification,
                "threat_level": threat_level,
                "confidence": confidence,
                "attack_indicators": attack_indicators,
                "recommendations": recommendations,
                "detailed_analysis": detailed_analysis
            }
            
        except Exception as e:
            logger.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            return {
                "timestamp": datetime.now().isoformat(),
                "log_id": log_data.get("timestamp", ""),
                "error": str(e),
                "classification": "ERROR",
                "threat_level": "UNKNOWN"
            }
    
    def _detect_attack_patterns(self, log_data: Dict[str, Any]) -> List[str]:
        attack_indicators = []
        url = log_data.get("request_url", "").lower()
        
        if any(pattern in url for pattern in ["'", "union", "select", "drop", "delete", "insert"]):
            attack_indicators.append("SQL_INJECTION")
        
        if any(pattern in url for pattern in ["<script", "javascript:", "alert(", "eval("]):
            attack_indicators.append("XSS")
        
        if any(pattern in url for pattern in ["../", "..", "etc/passwd", "windows/system32"]):
            attack_indicators.append("PATH_TRAVERSAL")
        
        if (log_data.get("user_role") == "INTERN" and 
            log_data.get("action_type") == "UPDATE" and 
            log_data.get("document_classification") in ["CONFIDENTIAL", "TOP_SECRET"]):
            attack_indicators.append("PRIVILEGE_ESCALATION")
        
        user_agent = log_data.get("request_headers", {}).get("User-Agent", "").lower()
        if any(tool in user_agent for tool in ["sqlmap", "nikto", "nmap", "burp"]):
            attack_indicators.append("AUTOMATED_SCAN")
        
        if log_data.get("request_count_per_minute", 0) > 100:
            attack_indicators.append("BRUTE_FORCE")
        
        return attack_indicators
    
    def _classify_request(self, log_data: Dict[str, Any], attack_indicators: List[str]) -> tuple:
        if attack_indicators:
            classification = "ATTACK"
            threat_level = self._calculate_threat_level(attack_indicators)
        elif log_data.get("access_result") == "PERMISSION_DENIED":
            classification = "EXCEPTION"
            threat_level = "LOW"
        elif log_data.get("access_result") == "SUCCESS":
            classification = "NORMAL"
            threat_level = "LOW"
        else:
            classification = "UNKNOWN"
            threat_level = "MEDIUM"
        
        return classification, threat_level
    
    def _calculate_threat_level(self, attack_indicators: List[str]) -> str:
        if not attack_indicators:
            return "LOW"
        
        high_risk = ["SQL_INJECTION", "PRIVILEGE_ESCALATION", "XSS"]
        medium_risk = ["PATH_TRAVERSAL", "AUTOMATED_SCAN"]
        
        if any(attack in high_risk for attack in attack_indicators):
            return "HIGH"
        elif any(attack in medium_risk for attack in attack_indicators):
            return "MEDIUM"
        else:
            return "LOW"
    
    def _calculate_confidence(self, log_data: Dict[str, Any], attack_indicators: List[str]) -> float:
        confidence = 0.5
        
        if attack_indicators:
            confidence += len(attack_indicators) * 0.1
        
        if log_data.get("access_result") == "BLOCKED":
            confidence += 0.2
        
        if log_data.get("security_events"):
            confidence += 0.2
        
        return min(confidence, 1.0)
    
    def _generate_recommendations(self, classification: str, attack_indicators: List[str], threat_level: str) -> List[str]:
        recommendations = []
        
        if classification == "ATTACK":
            recommendations.extend([
                "ì¦‰ì‹œ í•´ë‹¹ IP ì£¼ì†Œë¥¼ ì°¨ë‹¨í•˜ì„¸ìš”.",
                "ë³´ì•ˆ íŒ€ì— ì¦‰ì‹œ ì•Œë¦¼ì„ ë³´ë‚´ì„¸ìš”."
            ])
            
            if "SQL_INJECTION" in attack_indicators:
                recommendations.extend([
                    "ë°ì´í„°ë² ì´ìŠ¤ ì•¡ì„¸ìŠ¤ ë¡œê·¸ë¥¼ ê²€í† í•˜ì„¸ìš”.",
                    "SQL ì¸ì ì…˜ ë°©ì§€ íŒ¨ì¹˜ë¥¼ ì ìš©í•˜ì„¸ìš”."
                ])
            
            if "XSS" in attack_indicators:
                recommendations.extend([
                    "ì…ë ¥ ë°ì´í„° ê²€ì¦ì„ ê°•í™”í•˜ì„¸ìš”.",
                    "CSP(Content Security Policy) í—¤ë”ë¥¼ ì„¤ì •í•˜ì„¸ìš”."
                ])
            
            if "PRIVILEGE_ESCALATION" in attack_indicators:
                recommendations.extend([
                    "ê¶Œí•œ ê´€ë¦¬ ì‹œìŠ¤í…œì„ ì ê²€í•˜ì„¸ìš”.",
                    "í•´ë‹¹ ì‚¬ìš©ì ê³„ì •ì„ ì¼ì‹œ ì •ì§€í•˜ì„¸ìš”."
                ])
        
        elif classification == "EXCEPTION":
            recommendations.extend([
                "ì‚¬ìš©ì ê¶Œí•œ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.",
                "ì ‘ê·¼ ì œì–´ ì •ì±…ì„ ê²€í† í•˜ì„¸ìš”."
            ])
        
        else:
            recommendations.extend([
                "ì •ìƒ ìš”ì²­ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.",
                "ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ì„ ìœ ì§€í•˜ì„¸ìš”."
            ])
        
        return recommendations
    
    def _detailed_threat_analysis(self, log_data: Dict[str, Any]) -> Dict[str, Any]:
        url = log_data.get("request_url", "").lower()
        
        if any(pattern in url for pattern in ["'", "union", "select"]):
            attack_vector = "SQL_INJECTION"
        elif "<script" in url:
            attack_vector = "XSS"
        elif log_data.get("user_role") != log_data.get("expected_role"):
            attack_vector = "PRIVILEGE_ESCALATION"
        else:
            attack_vector = "UNKNOWN"
        
        classification = log_data.get("document_classification", "")
        action = log_data.get("action_type", "")
        
        if classification in ["TOP_SECRET", "CONFIDENTIAL"] and action in ["READ", "DELETE"]:
            impact = "CRITICAL"
        elif classification == "INTERNAL" and action in ["UPDATE", "DELETE"]:
            impact = "HIGH"
        else:
            impact = "MEDIUM"
        
        return {
            "attack_vector": attack_vector,
            "potential_impact": impact,
            "affected_resources": [
                f"Document: {log_data.get('document_id', 'N/A')}",
                f"User: {log_data.get('user_id', 'N/A')}"
            ]
        }


security_system = SecurityAnalysisSystem()

def validate_request_data(required_fields: List[str] = None) -> Dict[str, Any]:
    if required_fields is None:
        required_fields = ['timestamp', 'user_id', 'request_method', 'request_url']
    
    if not request.is_json:
        raise ValueError("Content-Type must be application/json")
    
    if not request.data or not request.data.decode('utf-8').strip():
        raise ValueError("Empty request body")
    
    try:
        data = request.get_json()
    except Exception as e:
        raise ValueError(f"Invalid JSON format: {str(e)}")
    
    if data is None:
        raise ValueError("Empty request body")
    
    missing_fields = [field for field in required_fields if field not in data]
    if missing_fields:
        raise ValueError(f"Missing required fields: {', '.join(missing_fields)}")
    
    return data

@app.route('/analyze', methods=['POST'])
def analyze_security_log():
    try:
        log_data = validate_request_data()
        result = security_system.analyze_log(log_data)
        
        if result.get('classification') == 'ATTACK':
            logger.info(f"ê³µê²© íƒì§€ë¨. ê³ ê¸‰ ë¶„ì„ìœ¼ë¡œ ì „í™˜: {result.get('threat_level', 'UNKNOWN')}")
            return analyze_security_log_advanced_internal(log_data)
        else:
            simple_report = security_system.generate_simple_report(result, log_data)
            result["report_path"] = simple_report
            
        logger.info(f"ë¶„ì„ ì™„ë£Œ: {result.get('classification', 'UNKNOWN')} - {result.get('threat_level', 'UNKNOWN')}")
        return jsonify(result)
        
    except ValueError as e:
        logger.warning(f"ì˜ëª»ëœ ìš”ì²­: {str(e)}")
        return jsonify({"error": str(e)}), 400
    except Exception as e:
        logger.error(f"ë¶„ì„ ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            "error": "Internal server error",
            "timestamp": datetime.now().isoformat()
        }), 500

@app.route('/analyze-advanced', methods=['POST'])
def analyze_security_log_advanced():
    try:
        log_data = validate_request_data()
        return analyze_security_log_advanced_internal(log_data)
        
    except ValueError as e:
        logger.warning(f"ì˜ëª»ëœ ìš”ì²­: {str(e)}")
        return jsonify({"error": str(e)}), 400
    except Exception as e:
        logger.error(f"ê³ ê¸‰ ë¶„ì„ ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return jsonify({
            "error": "Internal server error during advanced analysis",
            "timestamp": datetime.now().isoformat()
        }), 500

def analyze_security_log_advanced_internal(log_data):
    result = security_system.analyze_log_with_llm(log_data)
    
    classification = result.get('enhanced_classification', result.get('classification', 'UNKNOWN'))
    threat_level = result.get('enhanced_threat_level', result.get('threat_level', 'UNKNOWN'))
    
    logger.info(f"ê³ ê¸‰ ë¶„ì„ ì™„ë£Œ: {classification} - {threat_level}")
    logger.info(f"ë³´ê³ ì„œ ì €ì¥ ìœ„ì¹˜: {result.get('report_path', 'N/A')}")
    
    return jsonify(result)
            
@app.errorhandler(404)
def not_found(error):
    return jsonify({"error": "Endpoint not found"}), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({"error": "Internal server error"}), 500

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5001))
    debug = os.environ.get('FLASK_DEBUG', 'False').lower() == 'true'
    
    logger.info(f"ì„œë²„ ì‹œì‘: http://localhost:{port}")
    logger.info(f"ë³´ê³ ì„œ ì €ì¥ ë””ë ‰í† ë¦¬: {list(REPORT_DIRS.values())}")
    
    app.run(host='0.0.0.0', port=port, debug=debug)